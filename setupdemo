
关selinux 和 iptables
[root@base ~]# vi /etc/selinux/config
[root@base ~]# chkconfig iptables off

安装JDK(jdk-6u45-linux-i586-rpm.bin)配置环境/etc/profile
JAVA_HOME=/usr/java/jdk1.6.0_45
JRE_HOME=$JAVA_HOME/jre
PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib
export JAVA_HOME JRE_HOME PATH CLASSPATH

.bash_logout 配置用户登录出去执行什么
.bash_profile 配置用户特殊的profile
.bashrc 配置bash专用的(bash是一种shell linux 可以有很多种shell 比如C shell 就是C语言风格的shell 如果用C shell 这个文件就没用了)
############################################################################
配置/etc/sysconfig/network-scripts/ifcfg-eth0

DEVICE=eth0

#复制的虚拟机需要改这个硬件地址(也叫网卡的MAC地址)
HWADDR=00:0C:29:01:FF:78
TYPE=Ethernet
UUID=0ca7c5f6-daff-4f43-ae2b-d4155e687d60

#开机启动网卡
ONBOOT=yes

NM_CONTROLLED=yes

#使用静态IP配置
BOOTPROTO=static

#对应的子网广播地址
BROADCAST=192.168.36.255
#网卡对应的网段地址
NETWORK=192.168.36.0
#设置网卡获得的IP地址
IPADDR=192.168.36.129
#网卡对应的网络掩码
NETMASK=255.255.255.0
#设置Linux的网关(由虚拟机网络配置决定)
GATEWAY=192.168.36.2
#设置Linux的DNS(由虚拟机网络配置决定通常网关也是内网DNS，转发DNS请求)
DNS1=192.168.36.2

有外网测试安装setuptool
yum -y install setuptool
没有外网 ifconfig 看有否有 eth0 并且eth0 有IP 能ping通其他的虚拟机
############################################################################

修改/etc/hosts
192.168.36.130 master
192.168.36.131 slave1
192.168.36.132 slave2
192.168.36.133 slave3

修改 /etc/security/limits.conf 最后加 配置最大线程和文件打开数
* - nproc 65535
* - nofile 65535

确保创建了 hadoop 这个用户 执行以下命令
su - hadoop
mkdir ~/.ssh
cd ~/.ssh
ssh-keygen -t rsa -P ''

cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys

chmod 600 authorized_keys

root 用户编辑 /etc/ssh/sshd_config
vi /etc/ssh/sshd_config

去掉 26行 左右 以下配置的注释
HostKey /etc/ssh/ssh_host_rsa_key

去掉 47 48 49 行的注释 (对应下面这三行)


RSAAuthentication yes
PubkeyAuthentication yes
AuthorizedKeysFile      .ssh/authorized_keys

配置.ssh权限防止没权限读取ssh的秘钥
***一定要使用hadoop用户执行不能root代劳***


chown -R hadoop:hadoop /home/hadoop
chmod 700 /home/hadoop
chmod 700 /home/hadoop/.ssh
chmod 644 /home/hadoop/.ssh/authorized_keys
chmod 600 /home/hadoop/.ssh/id_rsa
############################################################################

hadoop 1.0.4 传到 虚拟机
放到 /home/hadoop 目录下
解压
tar -vxzf hadoop-1.0.4.tar.gz
修改解压后的目录名(mv 是移动文件 相当于改名)
mv hadoop-1.0.4 hadoop

mkdir ~/hadoop/data/
mkdir ~/hadoop/tmp/
chmod 755 ~/hadoop/data/
chmod 755 ~/hadoop/tmp/

配置hadoop用户目录下的 ~/.bash_profile
将以下内容编辑到文本末尾：
HADOOP_HOME=/home/hadoop/hadoop
PATH=$PATH:$HADOOP_HOME/bin
############################################################################
统一修改hadoop用户conf目录(~/hadoop/conf)下的各种配置文件

修改配置文件hadoop-env.sh
搜索到JAVA_HOME所在行，然后将默认的“#”去掉，也就是打开注释，然后如下配置：
export JAVA_HOME=/usr/java/jdk1.6.0_45

修改配置文件 core-site.xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- Put site-specific property overrides in this file. -->
<configuration>
 <property>
      <name>fs.default.name</name>
      <value>hdfs://master:9000</value>
 </property>
</configuration>

修改配置文件 hdfs-site.xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- Put site-specific property overrides in this file. -->
<configuration>
 <property>  
  <name>dfs.replication</name>
  <value>3</value>
 </property>            
 <property>  
   <name>dfs.name.dir</name>  
   <value>/home/hadoop/hadoop/namenode/</value>  
  </property> 
  <property>  
   <name>dfs.data.dir</name>  
   <value>/home/hadoop/hadoop/data/</value>  
  </property>               
  <property>  
    <name>hadoop.tmp.dir</name>  
    <value>/home/hadoop/hadoop/tmp/</value>  
  </property>
  <property>
   <name>dfs.permissions</name>
   <value>false</value>
  </property>
</configuration>

修改配置文件 mapred-site.xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- Put site-specific property overrides in this file. -->
<configuration>
 <property>  
   <name>mapred.job.tracker</name>  
   <value>master:9001</value>  
 </property>
 <property>  
   <name>mapred.tasktracker.map.tasks.maximum</name>  
   <value>2</value>  
 </property>                  
 <property>  
    <name>mapred.tasktracker.reduce.tasks.maximum</name>  
    <value>2</value>  
 </property>  
</configuration>

修改配置文件 masters
配置如下：
master

修改配置文件 slaves
配置如下：
slave1
slave2
slave3
############################################################################
复制4份虚拟机 并配置静态IP
vm_master 192.168.36.130
vm_slave1 192.168.36.131
vm_slave2 192.168.36.132
vm_slave3 192.168.36.133
############################################################################
hadoop namenode -format
启动hadoop：
start-all.sh
启动后使用jps命令查看：
NN上：
jps
namenode 1002
secondarynamenode 1011
jobtracker 1012
DN上：
jps
datanode 2
tasktracker 10
然后通过http://master:50070和http://master:50030查看监控界面。
